{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "6DN3gs3aT6Mg",
        "Oj4C8OMZT6Mh",
        "qO-PkgqyT6Mj",
        "CkbJdSYmT6Mk"
      ],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UuiKELEdT6MF"
      },
      "source": [
        "# Giới thiệu Convolution Nets\n",
        "\n",
        "Convolutional Neural Networks (CNN) là một trong những mô hình deep learning phổ biến nhất và có ảnh hưởng nhiều nhất trong cộng đồng Computer Vision. CNN được dùng trong trong nhiều bài toán như nhân dạng ảnh, phân tích video, ảnh MRI, hoặc cho bài các bài của lĩnh vự xử lý ngôn ngữ tự nhiên,và hầu hết đều giải quyết tốt các bài toán này. \n",
        "\n",
        "CNN cũng có lịch sử khá lâu đời. Kiến trúc gốc của mô hình CNN được giới thiệu bởi một nhà khoa học máy tính người Nhật vào năm 1980. Sau đó, năm 1998, Yan LeCun lần đầu huấn luyện mô hình CNN với thuật toán backpropagation cho bài toán nhận dạng chữ viết tay. Tuy nhiên, mãi đến năm 2012, khi một nhà khoa học máy tính người Ukraine Alex Krizhevsky (đệ của Geoffrey Hinton) xây dựng mô hình CNN (AlexNet) và sử dụng GPU để tăng tốc quá trình huấn luyện deep nets để đạt được top 1 trong cuộc thi Computer Vision thường niên ImageNet với độ lỗi phân lớp top 5 giảm hơn 10% so với những mô hình truyền thống trước đó, đã tạo nên làn sóng mãnh mẽ sử dụng deep CNN với sự hỗ trợ của GPU để giải quyết càng nhiều các vấn đề trong Computer Vision.\n",
        "\n",
        "# Bài Toán Phân loại Ảnh\n",
        "Phân loại ảnh là một bài toán quan trọng bậc nhất trong lĩnh vực Computer Vision. Chúng ta đã có rất nhiều nghiên cứu để giải quyết bài toán này bằng cách rút trích các đặc trưng rất phổ biến như SIFT, HOG rồi cho máy tính học nhưng những cách này tỏ ra không thực sự hiểu quả. Nhưng ngược lại, đối với con người, chúng ta lại có bản năng tuyệt vời để phân loại được những đối tượng trong khung cảnh xung quanh một cách dễ làm.\n",
        "\n",
        "Dữ liệu đầu vào của bài toán là một bức ảnh. Một ảnh được biểu ảnh bằng ma trận các giá trị. Mô hình phân lớp sẽ phải dự đoán được lớp của ảnh từ ma trận điểm ảnh này, ví dụ như ảnh đó là con mèo, chó, hay là chim.\n",
        "\n",
        "![](https://pbcquoc.github.io/images/cnn_input.png)\n",
        "\n",
        "# Nội dung \n",
        "Trong tut này, mình sẽ hướng dẫn các bạn xây dựng mô hình CNN (Convolution Neural Nets) cho bài toán phân loại ảnh. Các bạn sẽ sử dụng tensorflow [eager execution](https://www.tensorflow.org/guide/eager) để xây dựng model, huấn luyện mô hình trên tập train và predict ảnh trong tập test. \n",
        "\n",
        "Tut này sẽ có đi câú trúc như sau:\n",
        "1. Import dữ liệu\n",
        "2. Xây dựng mô hình\n",
        "3. Huấn luyện mô hình\n",
        "4. Đánh giá mô hình\n",
        "5. Sử dụng mô hình đã huấn luyện để dự đoán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1noDSEH2T6MG"
      },
      "source": [
        "# Import thư viện\n",
        "\n",
        "Chúng ta sử dụng một số hàm cơ bản trong tensorflow, sklearn và phải enable tf eage execution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lpEf76pvT6MH",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "np.warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.contrib.eager.python import tfe\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.set_random_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E-drPZYqT6MK"
      },
      "source": [
        "# Import và inspect dữ liệu\n",
        "Trong bài này, các bạn phải xây dựng mô hình để xác định các địa danh nổi tiếng trên lãnh thổ Việt Nam được mô tả trong bức ảnh. Tập dữ liệu huấn luyện bao gồm 20k ảnh, là một phần nhỏ của bộ dữ liệu trong cuộc thi ZaloAI năm 2018. \n",
        "\n",
        "Hình dưới mình họa một số địa danh nổi tiếng ở Việt Nam: Chùa một cột, vịnh hạ long\n",
        "![](https://github.com/pbcquoc/cnn/raw/master/img/smaple.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6kFHSLe3T6ML"
      },
      "source": [
        "## Download dữ liệu\n",
        "Dự liễu đã được tổ chức và chuyển thành dạng ma trận sẵn, các bạn chỉ việc tải về mà không cần phải load từ file raw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TCiEHjzHT6ML",
        "colab": {}
      },
      "source": [
        "gdd.download_file_from_google_drive(file_id='1ABhwNb5ioRzUEV9iLDpVSEIV_76yofNm', dest_path='./zaloai_landmark_20k.npz', unzip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iVuRanKET6MO",
        "colab": {}
      },
      "source": [
        "data = np.load(\"zaloai_landmark_20k.npz\")\n",
        "X, y = data['X'], data['y']\n",
        "\n",
        "num_classes = len(np.unique(y))\n",
        "y_ohe = tf.keras.utils.to_categorical(y, num_classes=num_classes, dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1nRDAfUNT6MQ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vjpnYIXRT6MT"
      },
      "source": [
        "## Chia dự liệu để huấn luyện và đánh giá\n",
        "Chúng ta sử dụng hàm train_test_split trong thư viện sklearn để chia tập dữ liệu thành 2 phần train/test một cách nhanh chóng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MtnwiHOZT6MU",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train_ohe, y_test_ohe = train_test_split(X, y_ohe, test_size=0.25)\n",
        "print(\"Train size: {} - Test size: {}\".format(x_train.shape, x_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "06g6e_u7T6MY"
      },
      "source": [
        "## Mô Hình CNN\n",
        "\n",
        "CNN bao gồm tập hợp các lớp cơ bản bao gồm: convolution layer + nonlinear layer, pooling layer, fully connected layer. Các lớp này liên kết với nhau theo một thứ tự nhất định. Thông thường, một ảnh sẽ được lan truyền qua tầng convolution layer + nonlinear layer đầu tiên, sau đó các giá trị tính toán được sẽ lan truyền qua pooling layer, bộ ba convolution layer + nonlinear layer + pooling layer có thể được lặp lại nhiều lần trong network. Và sau đó được lan truyền qua tầng fully connected layer và softmax để tính sác xuất ảnh đó chứa vật thế gì.\n",
        "\n",
        "![](https://pbcquoc.github.io/images/cnn_model.png)\n",
        "\n",
        "### Convolution Layer\n",
        "Convolution layer là lớp quan trọng nhất và cũng là lớp đầu tiên của của mô hình CNN. Lớp này có chức năng chính là phát hiện các đặc trưng có tính không gian hiệu quả. Trong tầng này có 4 đối tượng chính là: ma trận đầu vào, bộ **filters**, và **receptive field**, **feature map**. Conv layer nhận đầu vào là một ma trận 3 chiều và một bộ filters cần phải học. Bộ filters này sẽ trượt qua từng vị trí trên bức ảnh để tính tích chập (convolution) giữa bộ filter và phần tương ứng trên bức ảnh. Phần tưng ứng này trên bức ảnh gọi là receptive field, tức là vùng mà một neuron có thể nhìn thấy để đưa ra quyết định, và mà trận cho ra bới quá trình này được gọi là feature map. Để hình dung, các bạn có thể tưởng tượng, bộ filters giống như các tháp canh trong nhà tù quét lần lượt qua không gian xung quanh để tìm kiếm tên tù nhân bỏ trốn. Khi phát hiện tên tù nhân bỏ trốn, thì chuông báo động sẽ reo lên, giống như các bộ filters tìm kiếm được đặc trưng nhất định thì tích chập đó sẽ cho giá trị lớn. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://media.giphy.com/media/3orif7it9f4phjv4LS/giphy.gif\" />\n",
        "</div>\n",
        "\n",
        "Với ví dụ ở bên dưới, dữ liệu đầu vào ở là ma trận có kích thước 8x8x1, một bộ filter có kích thước 2x2x1, feature map có kích thước 7x7x1. Mỗi giá trị ở feature map được tính bằng tổng của tích các phần tử tương ứng của bộ filter 2x2x1 với receptive field trên ảnh. Và để tính tất cả các giá trị cho feature map, các bạn cần trượt filter từ trái sáng phải, từ trên xuống dưới. Do đó, các bạn có thể thấy rằng phép convolution bảo toàn thứ tự không gian của các điểm ảnh. ví dụ điểm góc gái của dữ liệu đầu vào sẽ tương ứng với bên một điểm bên góc trái của feature map. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://pbcquoc.github.io/images/cnn_covolution_layer.png\" />\n",
        "</div>\n",
        "\n",
        "#### Tầng convolution như là feature detector \n",
        "\n",
        "Tầng convolution có chức năng chính là phát hiện đặc trưng cụ thể của bức ảnh. Những đặc trưng này bao gồm đặc trưng cơ bản là góc,cạnh, màu sắc, hoặc đặc trưng phức tạp hơn như texture của ảnh. Vì bộ filter quét qua toàn bộ bức ảnh, nên những đặc trưng này có thể nằm ở vị trí bất kì trong bức ảnh, cho dù ảnh bị xoáy trái/phải thì những đặc trưng này vẫn bị phát hiện. \n",
        "\n",
        "Ở minh họa dưới, các bạn có một filter 5x5 dùng để phát hiện góc/cạnh với, filter này chỉ có giá trị một tại các điểm tương ứng một góc cong. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://pbcquoc.github.io/images/cnn_high_level_feature.png\" />\n",
        "</div>\n",
        "\n",
        "Dùng filter ở trên trược qua ảnh của nhân vật Olaf trong trong bộ phim Frozen. Chúng ta thấy rằng, chỉ ở những vị trí trên bức ảnh có dạng góc như đặc trưng ở filter thì mới có giá trị lớn trên feature map, những vị trí còn lại sẽ cho giá trị thấp hơn. Điều này có nghĩa là, filter đã phát hiện thành công một dạng góc/cạnh trên dự liệu đầu vào. Tập hơn nhiều bộ filters sẽ cho phép các bạn phát hiện được nhiều loại đặc trưng khác nhau,và giúp định danh được đối tượng. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://pbcquoc.github.io/images/cnn_high_level_feature_ex.png\" />\n",
        "</div>\n",
        "\n",
        "#### Các tham số của tầng convolution: Kích thước bộ filter, stride và padding\n",
        "\n",
        "Kích thước bộ filter là một trong những tham số quan trọng nhất của tầng convolution. Kích thước này tỉ lệ thuận với số tham số cần học tại mỗi tầng convolution và là tham số quyết định receptive field của tầng này. Kích thước phổ biến nhất của bộ filter là 3x3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CATPodwfT6MZ"
      },
      "source": [
        "# Xây dựng mô hình\n",
        "Các bạn cần phải xây dựng mô hình CNN có kiến trúc sau đây. Các bạn phải thỏa mãn bộ filter có kích thước 3x3. Đối với các tham số còn lại, các bạn có thể tự do lựa chọn để cho ra kết quả huấn luyện tốt nhất.\n",
        "\n",
        "![](https://github.com/pbcquoc/cnn/raw/master/images/cnn_architecture_2.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HCXKoRsNT6Ma"
      },
      "source": [
        "## Định nghĩa block CNN\n",
        "Để hỗ trợ quá trình định nghĩa mô hình. Các bạn cần định nghĩa một block bao gồm 3 lớp sau: Conv2D, MaxPool2D, ReLU. Block này sẽ được tái sử dụng nhiều lần trọng networks. Các layers cần được khai báo trong hàm init và được gọi trong hàm call. Hãy tham khảo ví dụ dưới đây.\n",
        "\n",
        "```python\n",
        "\n",
        "class ConvBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.cnn = tf.keras.layers.Conv2D(32, (3, 3), strides=(1, 1),  padding=\"same\")\n",
        "        \n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.cnn(inputs)\n",
        "\n",
        "        return x\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GkT5hTxjT6Mb",
        "colab": {}
      },
      "source": [
        "class ConvBlock(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel, strides, padding):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        ## TODO 1 ##\n",
        "        \n",
        "        ## END TODO 1 ##\n",
        "        self.cnn = tf.keras.layers.Conv2D(filters, (kernel, kernel), strides=(strides, strides), kernel_initializer='he_normal', padding=padding)\n",
        "        self.pool = tf.keras.layers.MaxPool2D((2,2), strides=(2,2))\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\n",
        "        \n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        ## TODO 2 ##\n",
        "        \n",
        "        ## END TODO 2 ##\n",
        "        x = self.cnn(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = tf.nn.relu(x)   \n",
        "        x = self.pool(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D1avJ7wvxpFq"
      },
      "source": [
        "## Định nghĩa toàn bộ mô hình CNN\n",
        "Các bạn sử dụng block ở trên để định nghĩa toàn bộ mô hình CNN có kiến trúc như hình dưới. Các layer cần được khởi tạo trong hàm init, và được gọi trong hàm call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fn6w7oh-T6Md",
        "colab": {}
      },
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        ## TODO 3 ##\n",
        "        ## END TODO 3 ##\n",
        "        self.block1 = ConvBlock(64, kernel=3, strides=1, padding='same')\n",
        "        self.block2 = ConvBlock(128, kernel=3, strides=1, padding='same')\n",
        "        self.block3 = ConvBlock(256, kernel=3, strides=1, padding='same')\n",
        "        self.block4 = ConvBlock(512, kernel=3, strides=1, padding='same')\n",
        "        self.block5 = ConvBlock(512, kernel=3, strides=1, padding='same')\n",
        "        self.block6 = ConvBlock(1024, kernel=3, strides=1, padding='same')\n",
        "        self.flatten = tf.layers.Flatten()\n",
        "        \n",
        "        ## TODO 4 ##\n",
        "        ## END TODO 4 ##\n",
        "        self.dense2 = tf.keras.layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        \n",
        "        ## TODO 5 ##\n",
        "        ## END TODO 5 ##\n",
        "        x = self.block1(inputs)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        ## TODO 6 ##\n",
        "        ## END TODO 6 ##   \n",
        "        x = self.dense2(x)\n",
        "        \n",
        "        # softmax op does not exist on the gpu, so always use cpu\n",
        "        with tf.device('/cpu:0'):\n",
        "            output = tf.nn.softmax(x)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HeV9Ab03T6Mk"
      },
      "source": [
        "# Huấn Luyện\n",
        "Đoạn code này thực hiện quá trình huấn luyện mô hình CNN. Mỗi lần chạy mô hình sẽ lấy batch_size mẫu dữ liệu, feedforward, tính loss, và cập nhật gradient cho toàn bộ trọng số. Toàn bộ quá trình này được thực hiện trong hàm fit()\n",
        "\n",
        "Sau khi huấn luyện xong, chúng ta sẽ đánh giá độ chính xác của mô hình bằng hàm evaluate()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXTU-2xPVhLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5tmZonE2T6Ml",
        "colab": {}
      },
      "source": [
        "device = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\n",
        "batch_size = 32\n",
        "epochs = 16\n",
        "\n",
        "with tf.device(device):\n",
        "    # build model and optimizer\n",
        "    model = CNN(num_classes)\n",
        "    model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    # TF Keras tries to use entire dataset to determine shape without this step when using .fit()\n",
        "    # Fix = Use exactly one sample from the provided input dataset to determine input/output shape/s for the model\n",
        "    \n",
        "#     dummy_x = tf.zeros((1, 224, 224, 3))\n",
        "#     model._set_inputs(dummy_x)\n",
        "#     model.summary()\n",
        "\n",
        "    # train\n",
        "    model.fit(x_train, y_train_ohe, batch_size=batch_size, epochs=epochs,\n",
        "              validation_data=(x_test, y_test_ohe), verbose=1)\n",
        "\n",
        "    # evaluate on test set\n",
        "    scores = model.evaluate(x_test, y_test_ohe, batch_size, verbose=1)\n",
        "    print(\"Final test loss and accuracy :\", scores)\n",
        "\n",
        "    model.save_weights('./check_points/my_model')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5p4QgrUJT6Mp"
      },
      "source": [
        "# Dự Đoán \n",
        "\n",
        "Chúng ta sử dụng mô hình đã được huấn luyện bên trên để dự đoán cho một ảnh bất kì. Đầu tiên là load lại bộ trọng số đã được huấn luyện. Sau đó, sử dụng mô hình này để dự đoán cho các ảnh mới. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VnnCTqhBT6Mq",
        "colab": {}
      },
      "source": [
        "model = CNN(num_classes)\n",
        "model.load_weights('./check_points/my_model')\n",
        "print(\"Model đã được load\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TBl_-M0_T6Mt",
        "colab": {}
      },
      "source": [
        "x_new = x_test[0]\n",
        "pred = model.predict(x_new[None, :])\n",
        "pred_label = np.argmax(pred)\n",
        "plt.imshow(x_new)\n",
        "print(\"Mô hình dự đoán nhãn của bức ảnh: {}\".format(pred_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhVAFRO3T6Nn",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}